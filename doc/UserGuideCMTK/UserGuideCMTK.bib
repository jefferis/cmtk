@String{ jan = {Jan.}}
@String{ feb = {Feb.}}
@String{ mar = {Mar.}}
@String{ apr = {Apr.}}
@String{ may = {May}}
@String{ jun = {Jun.}}
@String{ jul = {Jul.}}
@String{ aug = {Aug.}}
@String{ sep = {Sep.}}
@String{ oct = {Oct.}}
@String{ nov = {Nov.}}
@String{ dec = {Dec.}}

@string{ IEEE-TPAMI =  {IEEE Transactions on Pattern Analysis and Machine Intelligence} }
@String{ IEEE-TCE = {IEEE Transactions on Consumer Electronics}}
@string{ IEEE-TMI = {IEEE Transactions on Medical Imaging} }
@string{ IEEE-TMM = {IEEE Transactions on Multimedia} }
@string{ IEEE-TIP = {IEEE Transactions on Image Processing} }
@string{ IEEE-TBME = {IEEE Transactions on Biomedical Engineering} }
@string{ IEEE-TITB = {IEEE Transactions on Information Technology in Biomedicine} }
@string{ IEEE-TVCG = {IEEE Transactions on Visualization and Computer Graphics} }
@string{ IEEE-TSMC = {IEEE Transactions on Systems, Man and Cybernetics} }
@string{ IEEE-TSMCA = {IEEE Transactions on Systems, Man and Cybernetics, Part A} }
@string{ IEEE-TSMCB = {IEEE Transactions on Systems, Man and Cybernetics, Part B} }
@string{ IEEE-TNN = {IEEE Transactions on Neural Networks} }
@string{ IEEE-TSAP = {IEEE Transactions on Speech and Audio Processing} }
@string{ IEEE-TAC = {IEEE Transactions on Automatic Control} }
@string{ IEEE-SPM = {IEEE Signal Processing Magazine} }
@string{ IEEE-SPL = {IEEE Signal Processing Letters} }
@string{ IEEE-TSP = {IEEE Transactions on Signal Processing} }
@string{ IEEE-TIT = {IEEE Transactions on Information Theory} }
@string{ ProcIEEE = {Proceedings of the IEEE} }
@string{ IEEE-CGA = {IEEE Computer Graphics and Applications} }
@string{ IEEECOMP = {IEEE Computer} }
@string{ JCAT = {Journal of Computer Assisted Tomography} }
@string{ CVGIP = {Computer Vision, Graphics, and Image Processing} }
@string{ GraphModels = {Graphical Models} }
@string{ GMIP = {Graphical Models and Image Processing} }
@string{ CVIU = {Computer Vision and Image Understanding} }
@string{ MIA = {Medical Image Analysis} }
@string{ IJIST = {International Journal of Imaging Systems and Technology} }
@string{ CAS = {Computer Aided Surgery} }
@string{ MBEC =  {Med. Biol. Eng. Comput.} }
@string{ JNM = {Journal of Nuclear Medicine} }
@string{ ImageVisionComput = {Image and Vision Computing} }
@string{ MedPhys = {Medical Physics} }
@string{ Radiology = {Radiology} }
@string{ InvestRadiol = {Investigative Radiology} }
@string{ JIGS = {Journal of Image Guided Surgery} }
@string{ LARY = {Laryngoscope} }
@string{ JNR = {Journal of Neuroradiology} }
@string{ AJNR = {American Journal of Neuroradiology} }
@string{ ZNR = {Zentralblatt f\"ur Neurochirurgie} }
@string{ SE = {Surgical Endoscopy} }
@string{ JMRI = {Journal of Magnetic Resonance Imaging} }
@string{ MRI= {Magnetic Resonance Imaging} }
@string{ NCNA = {Neurosurgery Clinics of North America} }
@string{ AJS = {American Journal of Surgery} }
@string{ CJNS = {Canadian Journal of Neurological Sciences} }
@string{ JNI = {Journal of Neuroimaging} }
@string{ JNeuroimaging = {Journal of Neuroimaging} }
@string{ AJOL = {American Journal of Otolaryngology} }
@string{ ROI = {Radiation Oncology Investigations} }
@string{ BJR = {British Journal of Radiology} }
@string{ BJOMS = {British Journal of Oral and Maxillofacial Surgery} }
@string{ JNS = {Journal of Neurosurgery} }
@string{ JNSc = {The Journal of Neuroscience} }
@string{ JNScM = {Journal of Neuroscience Methods} }
@string{ JNeurosciMethods = {Journal of Neuroscience Methods} }
@string{ MolBrainRes = {Molecular Brain Research} }
@string{ NS = {Neurosurgery} }
@string{ EJR = {European Journal of Radiology} }
@string{ KlinNeurRad = {Klinische Neuroradiologie} }
@string{ MIUA = {Medical Image Understanding and Analysis} }
@string{ AJO = {American Journal of Otolaryngology}}
@string{ MiB = {Medizin im Bild}}
@string{ MVA = {Machine Vision and Applications} }
@string{ BiophysChem = {Biophysical Chemistry} }
@string{ PNAS = {Proceedings of the National Academy of Sciences of the U.S.A.} }
@string{ ACM-TOG = {ACM Transactions on Graphics} }
@string{ ACM-TOMS = {ACM Transactions on Mathematical Software} }
@string{ ACM-SGCG = {ACM SIGGRAPH Computer Graphics} }
@string{ ACMComputSurv = {ACM Computing Surveys} }
@string{ NeuroImage = {NeuroImage} }
@string{ RoeFo = {Fortschr R\"ontgenstr} }
@string{ PatRecog = {Pattern Recognition} }
@string{ PatRecogImageAnal = {Pattern Recognition and Image Analysis} }
@string{ PatRecogLett = {Pattern Recognition Letters} }
@string{ HumBrainMap = {Human Brain Mapping} }
@string{ NeuroSurg = {Neurosurgery} }
@string{ JCRCO = {Journal of Cancer Research and Clinical Oncology} }
@string{ RadOncBioPhys = {International Journal of Radiation Oncology Biology Physics} }
@string{ EurRadiol = {European Radiology}}
@string{ PhysMedBiol = {Physics in Medicine and Biology}}
@string{ IJROBP= {International Journal of Radiation Oncology, Biology, Physics}}
@string{ RO = {Radiotherapy Oncol}}
@string{ MRPBM = {Magnetic Resonance Materials in Physics, Biology and Medicine} }
@string{ AnnNuclMed = {Annals of Nuclear Medicine} }
@String{ AnnBiomedEng= {Annals of Biomedical Engineering}}
@string{ JNeurolNeurosurgPsychiatry = {Journal of Neurology, Neurosurgery, and Psychiatry} }
@string{ ComputMedImGraph = {Computerized Medical Imaging and Graphics} }
@string{ CompGraph = {Computer Graphics} }
@string{ SFN = {Stereotact Funct Neurosurg} }
@string{ JNNP = {Journal of Neurology, Neurosurgery, and Psychiatry} }
@string{ MRM = {Magnetic Resonance in Medicine} }
@string{ ParComput = {Parallel Computing} }
@string{ Neuron = {Neuron} }
@string{ JBI = {Journal of Biomedical Informatics}}
@string{ CMIG = {Computerized Medical Imaging and Graphics} }
@string{ IntJImagingSystTechnol = {International Journal of Imaging Systems and Technology} }
@string{ CommunACM = {Communications of the ACM} }
@string{ JACM = {Journal of the Association for Computing Machinery} }
@string{ JMicrosc = {Journal of Microscopy} }
@string{ AI = {Artificial Intelligence} }
@string{ JAmStatistAssoc = {Journal of the American Statistical Association} }
@string{ ComputJ = {Computer Journal} }
@string{ ActaRadiol = {Acta Radiologica} }
@string{ ComputBiolMed = {Computers in Biology and Medicine} }
@string{ IJCV = {International Journal of Computer Vision} }
@string{ ArtifIntellMed = {Artificial Intelligence in Medicine} }
@string{ ArtifIntellEng = {Artificial Intelligence in Engineering} }
@string{ InformFusion = {Information Fusion} }
@string{ IntelligentDataAnal = {Intelligent Data Analysis} }
@string{ SpeechCommun = {Speech Communication} }
@string{ PatternAnalAppl = {Pattern Analysis \& Applications} }
@string{ NeuralNetworks = {Neural Networks} }
@string{ NeuralComput = {Neural Computation} }
@string{ JElectronImaging = {Journal of Electronic Imaging} }
@string{ JNeurobiol = {Journal of Neurobiology} }
@string{ Lancet = {Lancet} }
@String{ ComputVisualSci = {Computing and Visualization in Science} }
@String{ MachLearn = {Machine Learning}}
@String{ AcadRadiol = {Academic Radiology}}
@String{ IJPRAI = {International Journal of Pattern Recognition and Artificial Intelligence}}
@String{ EJNM = {European Journal of Nuclear Medicine} }
@string{ JRoyalStatistSocB = {Journal of the Royal Statistical Society, Series B} }
@string{ IJIG = {International Journal of Image and Graphics} }
@string{ JAIR = {Journal of Artificial Intelligence Research} }
@string{ Spine = {Spine} }
@string{ LinearAlgebraApp = {Linear Algebra and its Applications}}
@string{ AmJRhinol = {American Journal of Rhinology} }
@string{ ConnectSci = {Connection Science} }
@string{ SeminRadiatOncol = {Seminars in Radiation Oncology} }
@string{ TCRT = {Technology in Cancer Research \& Treatment} }
@string{ AmJRoentgenol = {American Journal of Roentgenology}}
@string{ Neuroradiology = {Neuroradiology}}
@string { JInsectScience = {Journal of Insect Science} }
@string{ JMagnReson = {Journal of Magnetic Resonance} }
@string{ JMagnResonA = {Journal of Magnetic Resonance, Series A} }
@string{ JMagnResonB = {Journal of Magnetic Resonance, Series B} }
@string{ Nuklearmedizin = {Nuklearmedizin} }
@string{ Cell = {Cell}}
@string{ JBiomedOpt = {Journal of Biomedical Optics} }
@string{ NatBiotechnol = {Nature Biotechnology}}
@string{ Blood = {Blood}}
@string{ ProgNeurobiol = {Progress in Neurobiology}}
@string{ MicroscResTech = {Microscopy Research and Technique} }
@string{ ApplOpt = {Applied Optics} }
@string{ Methods =  {Methods} }
@string{ MechDev = {Mechanisms of Development} }
@string{ JCompNeurol = {Journal of Comparative Neurology} }
@string{ AlcoholClinExpRes = {Alcoholism: Clinical and Experimental Research}}
@string{ PPL = {Parallel Processing Letters} }
@string{ SchizophrRes = {Schizophrenia Research}}
@string{ AmJGeriatrPsychiatry = {American Journal of Geriatric Psychiatry} }
@string{ AmJPsychiatry = {American Journal of Psychiatry} }
@string{ AnnuRevBiomedEng = {Annual Review of Biomedical Engineering} }
@string{ AnalChem = {Analytical Chemistry} }
@string{ JMIV = {Journal of Mathematical Imaging and Vision} }
@string{ AnnNeurol = {Annals of Neurology} }
@string{ ClinOrthop = {Clinical Orthopaedics \& Related Research} }
@string{ JAnat = {Journal of Anatomy} }
@String{ AlcoholResHealth = {Alcohol Research \& Health}}
@String{ CerebCortex = {Cerebral Cortex}}
@String{ BrJPsychiatry = {The British Journal of Psychiatry}}
@String{ NMRBiomed = {NMR in Biomedicine}}
@String{ ImageAnalStereol = {Image Analysis \& Stereology} }
@string{ JCompPhys = {Journal of Computational Physics} }
@String{ JStudAlcohol = {Journal of Studies on Alcohol}}
@String{ JNeurolSci = {Journal of the Neurological Sciences}}
@String{ ArchNeurol = {Archives of Neurology}}
@String{ ArchGenPsychiatry = {Archives of General Psychiatry}}
@String{ NeurobiolAging = {Neurobiology of Aging}}
@String{ AmJHumBiol = {American Journal of Human Biology}}
@String{ BiolPsychol = {Biological Psychology}}
@String{ BiolPsychiatry = {Biological Psychiatry}}
@String{ NatNeurosci = {Nature Neuroscience}}
@String{ Neuroreport = {Neuroreport}}
@String{ CellTissueRes = {Cell and Tissue Research}}
@String{ TCRT = {Technology in Cancer Research \& Treatment}}
@String{ SFN = {Stereotactic and Functional Neurosurgery}}
@String{ Biometrics = {Biometrics}}
@String{ AnnMathStat = {Annals of Mathematical Statistics}}
@String{ PsychiatryResNeuroimaging = {Psychiatry Research: Neuroimaging}}
@String{ CurrOpinGenetDev = {Current Opinion in Genetics \& Development}}
@String{ ProcISMRM = {Proceedings of the International Society for Magnetic Resonance in Medicine}}
@String{ InverseProblems = {Inverse Problems}}
@String{ TrendsNeurosci = {Trends in Neuroscience}}
@String{ CurrOpinNeurobiol = {Current Opinion in Neurobiology}}
@String{ CellTissueRes = {Cell and Tissue Research}}
@String{ NatRevNeurosci = {Nature Reviews Neuroscience}}
@String{ AnnuRevNeurosci = {Annual Review of Neuroscience}}
@String{ TrendsCognSci = {Trends in Cognitive Sciences}}
@String{ JExpBiol = {Journal of Experimental Biology}}
@String{ LearnMem = {Learning Memory}}
@string{ JOSAA = {Journal of the Optical Society of America A}}
@String{ IOVS = {Investigative Ophthalmology \& Visual Science}}
@string{ ExpPhysiol = {Experimantal Physiology}}
@String{ AJRCCM = {American Journal of Respiratory and Critical Care Medicine}}
@String{ COACI = {Current Opinion in Allergy \& Clinical Immunology}}
@String{ MethodInformMed = {Methods of Information in Medicine}}
@String{ BiomechModelMechanobiol = {Biomechanics and Modeling in Mechanobiology}}
@String{ GenetEpidemiol = {Genetic Epidemiology}}
@String{ QApplMath = {Quarterly of Applied Mathematics}}
@String{ Bone = {Bone} }
@string{ Neuroscience = {Neuroscience}}
@String{ DrugAlcoholDepend = {Drug and Alcohol Dependence}}
@String{ ArtificialLife = {Artificial Life}}
@String{ Ecology = {Ecology}}
@String{ BMCMI = {BioMed Central Medical Imaging}}
@String{ AnatRec = {The Anatomical Record} }
@String{ Alcohol = {Alcohol}}
@String{ Teratology = {Teratology}}
@String{ Biometrika = {Biometrika}}
@String{ JRStatistSocB = {Journal of the Royal Statistical Society, Series B
                  (Methodological)}}
@String{ StatistSci = {Statistical Science}}
@String{ JExpBiol = {The Journal of Experimental Biology}}
@String{ IJBI = {International Journal of Biomedical Imaging}}
@String{ ComputGraphForum = {Computer Graphics Forum}}
@String{ BiophysJ = {Biophysical Journal}}
@string{ LNCS = {Lecture Notes in Computer Science} }
@String{ AnimCogn = {Animal Cognition}}
@String{ ChildDev = {Child Development}}
@String{ TrendsCognSci = {Trends in Cognitive Sciences}}
@String{ CognitPsychol = {Cognitive Psychology}}
@String{ Science = {Science}}
@String{ AnnNYAcadSci = {Annals of the New York Academy of Sciences}}
@String{ IntRevNeurobiol = {International Review of Neurobiology}}
@String{ PhilosTransRSocLondBBiolSci = {Philosophical Transactions of the
                  Royal Society of London. Series B, Biological Sciences}}
@String{ JAmMedInformAssoc = {Journal of the American Medical Informatics
                  Association}}
@String{ JOralMaxillofacSurg = {Journal of Oral and Maxillofacial Surgery}}
@String{ MathematicsMagazine = {Mathematics Magazine}}
@String{ NumericalAlgorithms = {Numerical Algorithms}}
@String{ Bioimaging = {Bioimaging}}
@String{ BMCBioinformatics = {BMC Bioinformatics}}
@String{ CurrBiol = {Current Biology}}
@String{ BrainResBull = {Brain Research Bulletin}}
@String{ BrainRes = {Brain Research}}
@String{ SIAM-JSC = {SIAM Journal on Scientific Computing}}
@String{ SIAM-JSSC = {SIAM Journal on Scientific and Statistical Computing}}
@String{ JMolGraphMod = {Journal of Molecular Graphics and Modelling}}
@String{ JSocIndustApplMath = {Journal of the Society for Industrial and Applied Mathematics}}
@String{ IntJMathStatSci = {International Journal of the Mathematical Statistics Sciences}}
@String{ JClinOncol = {Journal of Clinical Oncology}}
@String{ ElectronLett = {Electronics Letters}}
@String{ CVGIP-GMIP = {CVGIP: Graphical Models and Image Processing}}
@String{ MathComput = {Mathematics of Computation}}
@String{ AdvComputMath = {Advances in Computational Mathematics}}
@String{ JVision = {Journal of Vision}}
@String{ AnnuRevBiomedEng= {Annual Review of Biomedical Engineering}}
@String{ BrainImagingBehav = {Brain Imaging and Behavior}}
@String{ JGerontol = {Journal of Gerontology}}
@String{ JAmGeriatrSoc = {Journal of the American Geriatrics Society}}
@String{ IJBI = {International Journal of Biomedical Imaging}}
@String{ ProcSPIE = {Proceedings of SPIE}}
@String{ JGT = {Journal of Graphics Tools}}
@String{ Brain = {Brain}}
@String{ ArtifLife = {Artificial Life}}
@String{ Psychopharmacology = {Psychopharmacology}}

@Article{RohlMaur:2003,
  author = 	 {Rohlfing, Torsten and Maurer, Jr., Calvin R.},
  title = 	 {Nonrigid Image Registration in Shared-Memory Multiprocessor
                  Environments with Application to Brains, Breasts, and Bees},
  pages =        {16--25},
  volume =       7,
  number =       1,
  year =         2003,
  journal = 	 IEEE-TITB,
  abstract =     {One major problem with nonrigid image registration
                  techniques is their high computational cost. Because of
                  this, these methods have found limited application to
                  clinical situations where fast execution is required, e.g.,
                  intra-operative imaging. This paper presents a parallel
                  implementation of a nonrigid image registration
                  algorithm. It takes advantage of shared-memory
                  multiprocessor computer architectures using multithreaded
                  programming by partitioning of data and partitioning of
                  tasks, depending on the computational subproblem. For three
                  different biomedical applications (intra-operative brain
                  deformation, contrast-enhanced MR mammography, inter-subject
                  brain registration), the scaling behavior of the algorithm
                  is quantitatively analyzed. The method is demonstrated to
                  perform the computation of intra-operative brain deformation
                  in less than a minute using 64 CPUs on a 128-CPU
                  shared-memory supercomputer (SGI Origin 3800). It is shown
                  that its serial component is no more than 2 percent of the
                  total computation time, allowing a speedup of at least a
                  factor of 50. In most cases, the theoretical limit of the
                  speedup is substantially higher (up to 132-fold in the
                  application examples presented in this paper). The parallel
                  implementation of our algorithm is therefore capable of
                  solving nonrigid registration problems with short execution
                  time requirements and may be considered an important step
                  in the application of such techniques to clinically
                  important problems such as  the computation of brain
                  deformation during cranial image-guided surgery.},
  keywords =     {nonrigid image registration; high-performance computing;
                  multithreaded computations; parallel performance;
                  intra-operative brain deformation; contrast-enhanced MR
                  mammography; motion correction; inter-subject registration;
                  brain atlas},
  PMID =         {12670015},
  url =          {http://ieeexplore.ieee.org/xpls/abs_all.jsp?isNumber=26609&prod=JNL&arnumber=1186522&arSt=+16&ared=+25&arAuthor=Rohlfing%2C+T.%3B+Maurer%2C+C.R.%2C+Jr.&arNumber=1186522&a_id0=1186520&a_id1=1186521&a_id2=1186522&a_id3=1186523&a_id4=1186524&a_id5=1186525&a_id6=1186526&a_id7=1186527&count=8}
}

@Article{FranRuecSchn:2002,
  author = 	 {Frangi, Alejandro F. and Rueckert, Daniel and Schnabel,
                  Julia A. and Niessen, Wiro J.},
  title = 	 {Automatic construction of multiple-object three-dimensional
                  statistical shape models: application to cardiac modeling},
  journal = 	 IEEE-TMI,
  year = 	 2002,
  volume =	 21,
  number =	 9,
  pages =	 {1151--1166},
  month =	 sep,
  abstract =     {A novel method is introduced for the generation of landmarks
                  for three-dimensional (3-D) shapes and the construction of
                  the corresponding 3-D statistical shape models. Automatic
                  landmarking of a set of manual segmentations from a class of
                  shapes is achieved by 1) construction of an atlas of the
                  class, 2) automatic extraction of the landmarks from the
                  atlas, and 3) subsequent propagation of these landmarks to
                  each example shape via a volumetric nonrigid registration
                  technique using multiresolution B-spline deformations. This
                  approach presents some advantages over previously published
                  methods: it can treat multiple-part structures and requires
                  less restrictive assumptions on the structure's topology. In
                  this paper, we address the problem of building a 3-D
                  statistical shape model of the left and right ventricle of
                  the heart from 3-D magnetic resonance images.   The average
                  accuracy in landmark propagation is shown to be below 2.2
                  mm. This application demonstrates the robustness and
                  accuracy of the method in the presence of large shape
                  variability and multiple objects.},
  keywords =     {Atlas, cardiac models, model-based image analysis, nonrigid
                  registration, statistical shape models.},
  pdf =          {FranRuecSchn2002.pdf}
}

@InProceedings{FranRuecSchn:2001,
  author = 	 {Frangi, Alejandro F. and Rueckert, Daniel and Schnabel,
                  Julia A. and Niessen, Wiro J.},
  title = 	 {Automatic 3{D} {ASM} Construction via Atlas-Based Landmarking
                  and Volumetric Elastic Registration},
  booktitle = 	 {Information Processing in Medical Imaging: 17th
                  International Conference, IPMI 2001, Davis, CA, USA, June
                  18-22, 2001, Proceedings},
  pages =	 {78--91},
  year =	 2001,
  editor =	 {Insana, Michael F. and Leahy, Richard M.},
  volume =	 2082,
  series =	 LNCS,
  address =	 {Berlin/Heidelberg},
  publisher =	 {Springer-Verlag},
  abstract =	 {A novel method is introduced that allows for the generation
                  of landmarks for three-dimensional shapes and the
                  construction of the corresponding 3D Active Shape Models
                  (ASM). Landmarking of a set of examples from a class of
                  shapes is achieved by (i) construction of an atlas of the
                  class, (ii) automatic extraction of the landmarks from the
                  atlas, and (iii) subsequent propagation of these landmarks
                  to each example shape via a volumetric elastic deformation
                  procedure. This paper describes in detail the method to
                  generate the atlas, and the landmark extraction and
                  propagation procedures. This technique presents some
                  advantages over previously published methods: it can treat
                  multiple-part structures, and it requires less restrictive
                  assumptions on the structure's topology. The applicability
                  of the developed technique is demonstrated with two
                  examples: CT bone data and MR brain data.},
  keywords =	 {ASM; active shape model; non-rigid registration;
                  landmarking; atlas},
  pdf =          {FranRuecSchn2001.pdf}
}

@Article{RuecSonoHaye:1999,
  author = 	 {Rueckert, Daniel and Sonoda, Luke I. and Hayes, C. and
                  Hill, Derek L. G. and Leach, M. O. and Hawkes, David J.},
  title = 	 {Nonrigid Registration Using Free-Form Deformations:
                  Application to Breast {MR} Images},
  journal = 	 IEEE-TMI,
  year = 	 1999,
  volume =	 18,
  number =	 8,
  pages =	 {712--721},
  month =	 aug
}

@InProceedings{RohlRadePfef:2008a,
  author = 	 {Rohlfing, Torsten and Rademacher, Martin H. and Pfefferbaum,
                  A.},
  title = 	 {Volume reconstruction using inverse interpolation:
                  application to interleaved image motion correction},
  booktitle = 	 {Medical Image Computing and Computer-Assisted Intervention
                  --- MICCAI 2008. 11th International Conference, New York,
                  NY, USA, September 6-10, 2008, Proceedings, Part I},
  pages =	 {798--806},
  year = 	 2008,
  editor =	 {Metaxas, Dimitris and Axel, Leon and Fichtinger, Gabor and
                  Sz\'ekely, G\'abor},
  volume =	 5241,
  series = 	 LNCS,
  address = 	 {Berlin/Heidelberg},
  publisher =	 {Springer-Verlag},
  abstract =	 {We introduce in this work a novel algorithm for volume
                  reconstruction from data acquired on an irregular grid,
                  e.g., from multiple co-registered images. The algorithm,
                  which is based on an inverse interpolation formalism, is
                  superior to other methods in particular when the input
                  images have lower spatial resolution than the reconstructed
                  image. Local intensity bounds are enforced by an L-BFGSB
                  optimizer, regularize the reconstruction problem, and
                  preserve the intensity distribution of the input images.We
                  demonstrate the usefulness of our method by applying it to
                  retrospective motion correction in interleaved MR images.},
  doi =		 {10.1007/978-3-540-85988-8_95},
  url =          {http://www.springerlink.com/content/p5u464837t71r120},
  PMID =	 {18979819},
  PMC =          {2646840}
}

@Article{LikaVierPern:2001,
  author = 	 {Likar, Bostjan and Viergever, Max A. and Pernus, Franjo},
  title = 	 {Retrospective correction of {MR} intensity inhomogeneity
                  by information minimization},
  journal = 	 IEEE-TMI,
  year = 	 2001,
  volume =	 20,
  number =	 12,
  pages =	 {1398--1410},
  month =	 dec,
  abstract =	 {In this paper, the problem of retrospective correction of
                  intensity inhomogeneity in magnetic resonance (MR) images is
                  addressed. A novel model-based correction method is
                  proposed, based on the assumption that an image corrupted by
                  intensity inhomogeneity contains more information than the
                  corresponding uncorrupted image. The image degradation
                  process is described by a linear model, consisting of a
                  multiplicative and an additive component which are modeled
                  by a combination of smoothly varying basis functions. The
                  degraded image is corrected by the inverse of the image
                  degradation model. The parameters of this model are
                  optimized such that the information of the corrected image
                  is minimized while the global intensity statistic is
                  preserved. The method was quantitatively evaluated and
                  compared to other methods on a number of simulated and real
                  MR images and proved to be effective, reliable, and
                  computationally attractive. The method can be widely applied
                  to different types of MR images because it solely uses the
                  information that is naturally present in an image, without
                  making assumptions on its spatial and intensity
                  distribution. Besides, the method requires no preprocessing,
                  parameter setting, nor user interaction. Consequently, the
                  proposed method may be a valuable tool in MR image
                  analysis.},
  keywords =	 {MR image analysis; corrupted image; global intensity
                  statistic preservation; image degradation model; information
                  minimization; magnetic resonance imaging; medical diagnostic
                  imaging; model parameters; model-based correction method;
                  nonuniformity correction; parameter setting; retrospective
                  MR intensity inhomogeneity correction; smoothly varying
                  basis functions; user interaction},
  doi =		 {10.1109/42.974934}
}

@Article{ChanVese:2001,
  author = 	 {Chan, Tony F. and Vese, Lumita A.},
  title = 	 {Active Contours Without Edges},
  journal = 	 IEEE-TIP,
  year = 	 2001,
  volume =	 10,
  number =	 2,
  pages =	 {266--277},
  month =	 feb,
  abstract =	 {In this paper, we propose a new model for active contours to
                  detect objects in a given image, based on techniques of
                  curve evolution, Mumford-Shah functional for segmentation
                  and level sets. Our model can detect objects whose
                  boundaries are not necessarily defined by gradient.We
                  minimize an energy which can be seen as a particular case of
                  the minimal partition problem. In the level set formulation,
                  the problem becomes a ``mean-curvature flow''-like evolving
                  the active contour, which will stop on the desired
                  boundary. However, the stopping term does not depend on the
                  gradient of the image, as in the classical active contour
                  models, but is instead related to a particular segmentation
                  of the image.We will give a numerical algorithm using finite
                  differences. Finally, we will present various experimental
                  results and in particular some examples for which the
                  classical snakes methods based on the gradient are not
                  applicable. Also, the initial curve can be anywhere in the
                  image, and interior contours are automatically detected.},
  keywords =	 {Active contours, curvature, energy minimization, finite
                  differences, level sets, partial differential equations,
                  segmentation.},
  doi =		 {S 1057-7149(01)00819-3}
}

@PhdThesis{Rohlfing:2000,
  author = 	 {Rohlfing, Torsten},
  title = 	 {{Multimodale Datenfusion f\"ur die bildgesteuerte
                  Neurochirurgie und Strahlentherapie}},
  school = 	 {Technische Universit\"at Berlin},
  year = 	 2000
}

@Article{StudHillHawk:1997,
  author = 	 {Colin Studholme and Derek L.~G. Hill and David J. Hawkes},
  title = 	 {Automated three-dimensional registration of magnetic
		  resonance and positron emission tomography brain images by
		  multiresolution optimization of voxel similarity measures},
  journal =	 MedPhys,
  year =	 1997,
  volume =	 24,
  number =	 1,
  pages =	 {25--35},
  month =	 jan,
  keywords =     {automated registration, voxel similarity measures,
		  multiresolution optimization, magnetic resonance, positron
		  emission tomography}
}

@Article{StudHillHawk:1999,
  author = 	 {Colin Studholme and Derek~L.~G. Hill and David~J. Hawkes},
  title = 	 {An Overlap Invariant Entropy Measure of {3D} Medical Image
		  Alignment} ,
  journal =	 PatRecog,
  year =	 1999,
  volume =	 {32},
  number =       {1},
  pages =	 {71--86},
  keywords =     {Multi-modality, 3D Medical Images, Registration Criteria,
		  Information theory, Mutual Information, Normalisation},
  abstract =     {This paper is concerned with the development of
                  entropy-based registration criteria for automated 3D
                  multi-modality medical image alignment. In this application
                  where misalignment can be large with respect to the imaged
                  field of view, invariance to overlap statistics is an
                  important consideration. Current entropy measures are
                  reviewed and a normalised measure is proposed which is
                  simply the ratio of the sum of the marginal entropies and
                  the joint entropy. The effect of changing overlap on current
                  entropy measures and this normalised measure are compared
                  using a simple image model and experiments on clinical image
                  data. Results indicate that the normalised entropy measure
                  provides significantly improved behaviour over a range of
                  imaged fields of view.},
  doi =          {10.1016/S0031-3203(98)00091-0},
  keywords =     {Multi-modality; 3D medical images; Registration criteria;
                  Information theory; Entropy; Mutual information;
                  Normalisation}
}

@Article{MaesCollVand:1997,
  author = 	 {Maes, F. and Collignon, A. and Vandermeulen, D. and Marchal, 
                  G. and Suetens, P.},
  title = 	 {Multimodality image registration by maximisation of mutual
                  information},
  journal = 	 IEEE-TMI,
  year = 	 1997,
  volume =	 16,
  number =	 2,
  pages =	 {187--198}
}

@Article{WellViolAtsu:1996,
  author = 	 {Wells, William M. and Viola, Paul A. and Atsumi, Hideki and
		  Nakajima, Shin and Kikinis, Ron},
  title = 	 {Multi-Modal Volume Registration by Maximization of Mutual
		  Information},
  journal =	 MIA,
  year =	 1996,
  volume =	 1,
  number =	 1,
  pages =        {35--51},
  publisher =    {Oxford University Press},
  month =	 mar,
  abstract =	 {A new information-theoretic approach is presented for
                  finding the registration of volumetric medical images of
                  differing modalities. Registration is achieved by adjustment
                  of the relative position and orientation until the mutual
                  information between the images is maximized. In our
                  derivation of the registration procedure, few assumptions
                  are made about the nature of the imaging process. As a
                  result the algorithms are quite general and can foreseeably
                  be used with a wide variety of imaging devices. This
                  approach works directly with image data; no pre-processing
                  or segmentation is required. This technique is, however,
                  more flexible and robust than other intensity-based
                  techniques like correlation. Additionally, it has an
                  efficient implementation that is based on stochastic
                  approximation. Experiments are presented that demonstrate
                  the approach registering magnetic resonance (MR) images with
                  computed tomography (CT) images, and with positron-emission
                  tomography (PET) images. Surgical applications of the
                  registration method are described.},
  keywords =	 {Information Theory; Multi-Modality Volume Registration;
                  Mutual Information},
  doi =		 {10.1016/S1361-8415(01)80004-9}}
}

@InProceedings{RochMalaPenn:1998a,
  author = 	 {Roche, Alexis and Malandain, Gregoire and Pennec, Xavier and
                  Ayache, Nicholas},
  title = 	 {The Correlation Ratio as a New Similarity Measure for
                  Multimodal Image Registration},
  booktitle = 	 {Medical Image Computing and Computer-Assisted Intervention -
                  MICCAI'98, First International Conference, Cambridge, MA,
                  USA, October 11-13, 1998, Proceedings},
  pages =	 {1115--1124},
  year =	 1998,
  editor =	 {Wells, III., William M. and Colchester, Alan C. F. and Delp,
                  Scott},
  volume =	 1496,
  series =	 LNCS,
  publisher =	 {Springer-Verlag},
  abstract =	 {Over the last five years, new ``voxel-based'' approaches
                  have allowed important progress in multimodal image
                  registration, notably due to the increasing use of
                  information-theoretic similarity measures. Their wide
                  success has led to the progressive abandon of measures using
                  standard image statistics (mean and variance). Until now,
                  such measures have essentially been based on heuristics. In
                  this paper, we address the determination of a new measure
                  based on standard statistics from a theoretical point of
                  view. We show that it naturally leads to a known concept of
                  probability theory, the correlation ratio. In our
                  derivation, we take as the hypothesis the functional
                  dependence between the image intensities. Although such a
                  hypothesis is not as general as possible, it enables us to
                  model the image smoothness prior very easily. We also
                  demonstrate results of multimodal rigid registration
                  involving Magnetic Resonance (MR), Computed Tomography (CT),
                  and Positron Emission Tomography (PET) images. These results
                  suggest that the correlation ratio provides a good trade-off
                  between accuracy and robustness.},
  keywords =	 {registration, matching, multimodal, correlation ratio}
}

@Article{AlpeBradKenn:1990,
  author = 	 {Alpert, N. M. and Bradshaw, J. F. and Kennedy, D. and
                  Correia, J. A.},
  title = 	 {The Principal Axes Transformation -- A Method for Image
                  Registration},
  journal = 	 JNM,
  year = 	 1990,
  volume =	 31,
  number =	 10,
  pages =	 {1717--1722},
  abstract =	 {We have developed a computational technique suitable for
                  registration of sets of image data covering the whole brain
                  volume which are translated and rotated with respect to one
                  another. The same computational method may be used to
                  register pairs of tomographic brain images which are rotated
                  and translated in the transverse section plane. The
                  technique is based on the classical theory of rigid bodies,
                  employing as its basis the principal axes
                  transformation. The performance of the method was studied by
                  simulation and with image data from PET, XCT, and MRI. It
                  was found that random errors in determining the brain
                  contour are well tolerated. Progressively coarser axial
                  sampling of data sets led to some degradation, but
                  acceptable performance was obtained with axial sampling
                  distances up to 10 mm. Given adequate digital sampling of
                  the object volume, we conclude that registration by the
                  principal axes transformation can be accomplished with
                  typical errors in the range of ~1 mm. The advantages of the
                  technique are simplicity and speed of computation.}
}

@InProceedings{RussTomaRohl:2004,
  author = 	 {Russakoff, Daniel B. and Tomasi, Carlo and Rohlfing, Torsten
                  and Maurer, Jr., Calvin R.},
  title = 	 {Image Similarity Using Mutual Information of Regions},
  booktitle = 	 {Computer Vision - ECCV 2004: 8th European Conference on
                  Computer Vision, Prague, Czech Republic, May 11-14,
                  2004. Proceedings, Part III},
  pages =	 {596--607},
  year =	 2004,
  volume =	 3023,
  series =	 LNCS,
  address =	 {Berlin/Heidelberg},
  publisher =	 {Springer-Verlag},
  abstract =	 {Mutual information (MI) has emerged in recent years as an
                  effective similarity measure for comparing images. One
                  drawback of MI, however, is that it is calculated on a pixel
                  by pixel basis, meaning that it takes into account only the
                  relationships between corresponding individual pixels and
                  not those of each pixels respective neighborhood. As a
                  result, much of the spatial information inherent in images
                  is not utilized. In this paper, we propose a novel extension
                  to MI called regional mutual information (RMI). This
                  extension efficiently takes neighborhood regions of
                  corresponding pixels into account. We demonstrate the
                  usefulness of RMI by applying it to a real-world problem in
                  the medical domain -- intensity-based 2D-3D registration of
                  X-ray projection images (2D) to a CT image (3D). Using a
                  gold-standard spine image data set, we show that RMI is a
                  more robust similarity meaure for image registration than
                  MI.},
  keywords =	 {intensity-based registration; mutual information;
                  high-dimensional entropy; pixel neighborhood},
  url =          {http://www.springerlink.com/openurl.asp?genre=article&issn=0302-9743&volume=3023&spage=596}
}

@Article{MaurQiRagh:2003,
  author = 	 {Maurer, Jr., Calvin R. and Qi, Rensheng and Raghavan,
                  Vijay},
  title = 	 {A linear time algorithm for computing exact {Euclidean}
                  distance transforms of binary images in arbitrary
                  dimensions},
  journal = 	 IEEE-TPAMI,
  year = 	 2003,
  volume =	 25,
  number =	 2,
  pages =	 {265--270},
  month =	 feb,
  abstract =	 {A sequential algorithm is presented for computing the exact
                  Euclidean distance transform (DT) of a k-dimensional binary
                  image in time linear in the total number of voxels N. The
                  algorithm, which is based on dimensionality reduction and
                  partial Voronoi diagram construction, can be used for
                  computing the DT for a wide class of distance functions,
                  including the L/sub p/ and chamfer metrics. At each
                  dimension level, the DT is computed by constructing the
                  intersection of the Voronoi diagram whose sites are the
                  feature voxels with each row of the image. This construction
                  is performed efficiently by using the DT in the next lower
                  dimension. The correctness and linear time complexity are
                  demonstrated analytically and verified experimentally. The
                  algorithm may be of practical value since it is relatively
                  simple and easy to implement and it is relatively fast (not
                  only does it run in O(N) time but the time constant is
                  small). A simple modification of the algorithm computes the
                  weighted Euclidean DT, which is useful for images with
                  anisotropic voxel dimensions. A parallel version of the
                  algorithm runs in O(N/p) time with p processors.},
  keywords =	 {computational complexity; computational geometry; image
                  processing; transforms; Voronoi diagram; anisotropic voxel
                  dimensions; binary images; chamfer metrics; dimensionality
                  reduction; exact Euclidean DT; exact Euclidean distance
                  transform computation; feature voxels; linear time
                  algorithm; linear time complexity; multidimensional binary
                  image; partial Voronoi diagram construction}
}

@Article{BranRohlRyba:2005,
  author = 	 {Brandt, Robert and Rohlfing, Torsten and Rybak, J\"urgen and
                  Krofczik, Sabine and Maye, Alexander and Westerhoff, Malte
                  and Hege, Hans-Christian and Menzel, Randolf},
  title = 	 {Three-dimensional average-shape atlas of the honeybee brain
                  and its applications},
  year =         2005,
  journal = 	 JCompNeurol,
  volume =	 492,
  number =	 1,
  pages =	 {1--19},
  month =	 nov,
  abstract =	 {The anatomical substrates of neural nets are usually
                  composed from reconstructions of neurons that were stained
                  in different preparations. Realistic models of the
                  structural relationships between neurons require a common
                  framework. Here we present 3-D reconstructions of single
                  projection neurons (PN) connecting the antennal lobe (AL)
                  with the mushroom body (MB) and lateral horn, groups of
                  intrinsic mushroom body neurons (type 5 Kenyon cells), and a
                  single mushroom body extrinsic neuron (PE1), aiming to
                  compose components of the olfactory pathway in the
                  honeybee. To do so, we constructed a digital standard atlas
                  of the bee brain. The standard atlas was created as an
                  average-shape atlas of 22 neuropils, calculated from 20
                  individual immunostained whole-mount bee brains. After
                  correction for global size and positioning differences by
                  repeatedly applying an intensity-based nonrigid registration
                  algorithm, a sequence of average label images was
                  created. The results were qualitatively evaluated by
                  generating average gray-value images corresponding to the
                  average label images and judging the level of detail within
                  the labeled regions. We found that the first affine
                  registration step in the sequence results in a blurred image
                  because of considerable local shape differences. However,
                  already the first nonrigid iteration in the sequence
                  corrected for most of the shape differences among
                  individuals, resulting in images rich in internal detail. A
                  second iteration improved on that somewhat and was selected
                  as the standard. Registering neurons from different
                  preparations into the standard atlas reveals 1) that the
                  m-ACT neuron occupies the entire glomerulus (cortex and
                  core) and overlaps with a local interneuron in the cortical
                  layer; 2) that, in the MB calyces and the lateral horn of
                  the protocerebral lobe, the axon terminals of two identified
                  m-ACT neurons arborize in separate but close areas of the
                  neuropil; and 3) that MB-intrinsic clawed Kenyon cells (type
                  5), with somata outside the calycal cups, project to the
                  peduncle and lobe output system of the MB and contact
                  (proximate) the dendritic tree of the PE1 neuron at the base
                  of the vertical lobe. Thus the standard atlas and the
                  procedures applied for registration serve the function of
                  creating realistic neuroanatomical models of parts of a
                  neural net. The Honeybee Standard Brain is accessible at
                  www.neurobiologie.fu-berlin.de/beebrain.},
  keywords =	 {virtual neuroanatomy; insect brain; brain atlas; brain
                  reference system; mushroom bodies; antennal lobe; olfactory
                  system},
  doi =		 {10.1002/cne.20644},
  PMID =         {16175557}
}

@Article{KuryRohlKrof:2008,
  author = 	 {Kurylas, Angela E. and Rohlfing, T. and Krofczik, Sabine and
                  Jenett, Arnim and Homberg, Uwe},
  title = 	 {Standardized atlas of the brain of the desert locust,
                  Schistocerca gregaria},
  journal = 	 CellTissueRes,
  year = 	 2008,
  volume =	 333,
  number =	 1,
  pages =	 {125-145},
  month =	 jul,
  abstract =	 {In order to understand the connectivity of neuronal
                  networks, their constituent neurons should ideally be
                  studied in a common framework. Since morphological data from
                  physiologically characterized and stained neurons usually
                  arise from different individual brains, this can only be
                  performed in a virtual standardized brain that compensates
                  for interindividual variability. The desert locust,
                  Schistocerca gregaria, is an insect species used widely for
                  the analysis of olfactory and visual signal processing,
                  endocrine functions, and neural networks controlling motor
                  output. To provide a common multi-user platform for neural
                  circuit analysis in the brain of this species, we have
                  generated a standardized three-dimensional brain of this
                  locust. Serial confocal images from whole-mount locust
                  brains were used to reconstruct 34 neuropil areas in ten
                  brains. For standardization, we compared two different
                  methods: an iterative shape-averaging (ISA) procedure by
                  using affine transformations followed by iterative nonrigid
                  registrations, and the Virtual Insect Brain (VIB) protocol
                  by using global and local rigid transformations followed by
                  local nonrigid transformations. Both methods generated a
                  standard brain, but for different applications. Whereas the
                  VIB technique was designed to visualize anatomical
                  variability between the input brains, the purpose of the ISA
                  method was the opposite, i.e., to remove this variability. A
                  novel individually labeled neuron, connecting the lobula to
                  the midbrain and deutocerebrum, has been registered into the
                  ISA atlas and demonstrates its usefulness and accuracy for
                  future analysis of neural networks. The locust standard
                  brain is accessible at http://www.3d-insectbrain.com.},
  keywords =	 {Virtual Insect Brain protocol; Iterative shape averaging;
                  Three-dimensional reconstruction; Standard brain; Virtual
                  neuroanatomy; Schistocerca gregaria (Insecta)},
  doi =		 {10.1007/s00441-008-0620-x},
  PMID = 	 18504618,
  url =          {http://www.springerlink.com/index/10.1007/s00441-008-0620-x}
}

@InProceedings{RohlBranMaur:2001,
  author = 	 {Rohlfing, Torsten and Brandt, Robert and Maurer, Jr., Calvin
                  R. and Menzel, Randolf},
  title = 	 {Bee Brains, {B}-Splines and Computational Democracy:
                  Generating an Average Shape Atlas},
  booktitle = 	 {IEEE Workshop on Mathematical Methods in Biomedical Image
                  Analysis},
  pages =	 {187--194},
  year =	 2001,
  editor =	 {Staib, Lawrence},
  address =	 {Kauai, HI},
  organization = {IEEE Computer Society, Los Alamitos, CA},
  isbn =         {0-7695-1336-0},
  abstract =     {We describe a method to generate an average atlas from
                  segmented 3-D images of a population of subjects. Using
                  repeated application of an intensity-based non-rigid
                  registration algorithm based on third-order 3-D B-splines, a
                  sequence of average label images is created. Averaging of
                  the non-numerical label data employs a generalization of the
                  mode of sets of corresponding voxels, parameterized by a
                  threshold value specifying the required level of
                  classification confidence. The number of voxels that cannot
                  be assigned a unique average value provides a criterion for
                  the convergence of the iteration. For improved accuracy,
                  efficiency, and robustness of the non-rigid registration,
                  deformations computed during one iteration are propagated to
                  the next iteration as initial transformation estimates. The
                  usefulness of our method is demonstrated by applying it to
                  generate an average atlas from segmented 3-D confocal
                  microscopy images of 20 bee brains. We validate that the
                  deformations found by our algorithm are meaningful by
                  deforming the original gray-level images according to the
                  transformations computed for the label fields.},
  keywords =     {bio-optics; brain; convergence of numerical methods; image
                  registration; image segmentation; interpolation; iterative
                  methods; medical image processing; optical microscopy;
                  probability; splines (mathematics); zoology; average label
                  images; average shape atlas; bee brains; classification
                  confidence; computational democracy; confocal microscopy
                  images; gray-level; honeybees; image registration;
                  intensity-based nonrigid registration algorithm;
                  interpolation; iterative averaging; probability
                  distribution; segmented 3-D images; third-order 3-D
                  B-splines},
  url =          {http://ieeexplore.ieee.org/xpls/abs_all.jsp?isNumber=21385&prod=CNF&arnumber=991733&arSt=187&ared=194&arAuthor=Rohlfing%2C+T.%3B+Brandt%2C+R.%3B+Maurer%2C+C.R.%2C+Jr.%3B+Menzel%2C+R.&arNumber=991733&a_id0=991707&a_id1=991708&a_id2=991709&a_id3=991710&a_id4=991711&a_id5=991712&a_id6=991731&a_id7=991732&a_id8=991733&a_id9=991734&a_id10=991735&a_id11=991736&a_id12=991737&a_id13=991738&a_id14=991739&count=15},
  doi =          {10.1109/MMBIA.2001.991733}
}

@Article{GuimMeunThir:2000,
  author = 	 {Guimond, Alexandre and Meunier, Jean and Thirion,
                  Jean-Philippe},
  title = 	 {Average Brain Models: A Convergence Study },
  journal = 	 CVIU,
  year = 	 2000,
  volume =	 77,
  number =	 2,
  pages =	 {192--210},
  month =	 feb,
  abstract =	 {We present a completely automatic method to build stable
                  average anatomical models of the human brain using a set of
                  magnetic resonance (MR) images. The models computed present
                  two important characteristics: an average intensity and an
                  average shape, both in a single image. We provide results
                  showing convergence toward the centroid of the image set
                  used for the computation of the model. In particular, the
                  RMS distances between the model and the MR images contained
                  in the set stabilize in a range of 2.88 to 3.36 mm from a
                  range of 4.62 to 5.51 mm initially after only one
                  iteration. As for the influence of the reference image
                  chosen for the model construction, this is minimal with
                  differences of about 1.0 mm, from approximately 3.5 mm
                  initially. These results ensure the usefulness of our
                  approach.},
  keywords =	 {shape; average shape; brain},
  doi =		 {10.1006/cviu.1999.0815}
}

@InProceedings{BalcGollShen:2007,
  author = 	 {Balci, Serdar K. and Golland, Polina and Shenton, Martha and
                  Wells, William M.},
  title = 	 {Free-Form {B}-spline Deformation Model for Groupwise
                  Registration},
  booktitle = 	 {MICCAI 2007 Workshop Statistical Registration: Pair-wise and
                  Group-wise Alignment and Atlas Formation},
  pages =	 {23--30},
  year =	 2007,
  abstract =	 {In this work, we extend a previously demonstrated entropy
                  based groupwise registration method to include a free-form
                  deformation model based on B-splines. We provide an
                  efficient implementation using stochastic gradient descents
                  in a multi-resolution setting. We demonstrate the method in
                  application to a set of 50 MRI brain scans and compare the
                  results to a pairwise approach using segmentation labels to
                  evaluate the quality of alignment. Our results indicate that
                  increasing the complexity of the deformation model improves
                  registration accuracy significantly, especially at cortical
                  regions.}
}

@Article{Learned-Miller:2006,
  author = 	 {Learned-Miller, Erik G.},
  title = 	 {Data driven image models through continuous joint
                  alignment},
  journal = 	 IEEE-TPAMI,
  year = 	 2006,
  volume =	 28,
  number =	 2,
  pages =	 {236--250},
  month =	 feb,
  abstract =	 {This paper presents a family of techniques that we call
                  congealing for modeling image classes from data. The idea is
                  to start with a set of images and make them appear as
                  similar as possible by removing variability along the known
                  axes of variation. This technique can be used to eliminate
                  ``nuisance'' variables such as affine deformations from
                  handwritten digits or unwanted bias fields from magnetic
                  resonance images. In addition to separating and modeling the
                  latent images - i.e., the images without the nuisance
                  variables - we can model the nuisance variables themselves,
                  leading to factorized generative image models. When nuisance
                  variable distributions are shared between classes, one can
                  share the knowledge learned in one task with another task,
                  leading to efficient learning. We demonstrate this process
                  by building a handwritten digit classifier from just a
                  single example of each class. In addition to applications in
                  handwritten character recognition, we describe in detail the
                  application of bias removal from magnetic resonance
                  images. Unlike previous methods, we use a separate,
                  nonparametric model for the intensity values at each
                  pixel. This allows us to leverage the data from the MR
                  images of different patients to remove bias from each
                  other. Only very weak assumptions are made about the
                  distributions of intensity values in the images. In addition
                  to the digit and MR applications, we discuss a number of
                  other uses of congealing and describe experiments about the
                  robustness and consistency of the method.},
  keywords =	 {artifact removal; bias removal; clustering; congealing;
                  correspondence; density estimation; entropy; magnetic
                  resonance imaging; maximum likelihood; medical imaging;
                  nonparametric statistics; registration; unsupervised
                  learning},
  doi =		 {10.1109/TPAMI.2006.34}
}

@InProceedings{RohlZahrSull:2008,
  author = 	 {Rohlfing, Torsten and Zahr, Natalie M. and Sullivan, Edith
                  V. and Pfefferbaum, Adolf},
  title = 	 {The {SRI24} Multi-Channel Brain Atlas: Construction and
                  Applications},
  booktitle = 	 {Medical Imaging 2008: Image Processing},
  eid =          691409,
  year = 	 2008,
  editor =	 {Reinhardt, Joseph M. and Pluim, Josien P. W.},
  volume =	 6914,
  series =	 ProcSPIE,
  address =	 {Bellingham, WA},
  abstract =	 {We present a new standard atlas of the human brain based on
                  magnetic resonance images. The atlas was generated using
                  unbiased population registration from high-resolution images
                  obtained by multichannel-coil acquisition at 3T in a group
                  of 24 normal subjects. The final atlas comprises three
                  anatomical channels (T1-weighted, early and late spin echo),
                  three diffusion-related channels (fractional anisotropy,
                  mean diffusivity, diffusion-weighted image), and three
                  tissue probability maps (CSF, gray matter, white
                  matter). The atlas is dynamic in that it is implicitly
                  represented by nonrigid transformations between the 24
                  subject images, as well as distortion-correction alignments
                  between the image channels in each subject. The atlas can,
                  therefore, be generated at essentially arbitrary image
                  resolutions and orientations (e.g., AC/PC aligned), without
                  compounding interpolation artifacts. We demonstrate in this
                  paper two different applications of the atlas: (a) region
                  definition by label propagation in a fiber tracking study is
                  enabled by the increased sharpness of our atlas compared
                  with other available atlases, and (b) spatial normalization
                  is enabled by its average shape property. In summary, our
                  atlas has unique features and will be made available to the
                  scientific community as a resource and reference system for
                  future imaging-based studies of the human brain.},
numpages = 12,
pages = 691409,
location = {San Diego, CA, USA},
url = {http://link.aip.org/link/?PSI/6914/691409/1},
  doi =		 {10.1117/12.770441},
  pdf =          {2008-rohlfing-spie-sri24_atlas.pdf},
  category =  {conference},
  PMID =         19183706,
  PMC =          {2633114}
}

@Article{RohlZahrSull:2010,
  author = 	 {Rohlfing, Torsten and Zahr, Natalie M. and Sullivan, Edith
                  V. and Pfefferbaum, Adolf},
  title = 	 {The {SRI24} Multichannel Atlas of Normal Adult Human Brain
                  Structure},
  journal = 	 HumBrainMap,
  year = 	 2010,
  volume =	 31,
  number =	 5,
  pages = 	 {798-819},
  month =	 May,
  abstract =	 {This article describes the SRI24 atlas, a new standard
                  reference system of normal human brain anatomy, that was
                  created using template-free population registration of
                  high-resolution magnetic resonance images acquired at 3T in
                  a group of 24 normal control subjects. The atlas comprises
                  anatomical channels (T1, T2, and proton density weighted),
                  diffusion-related channels (fractional anisotropy, mean
                  diffusivity, longitudinal diffusivity, mean
                  diffusion-weighted image), tissue channels (CSF probability,
                  gray matter probability, white matter probability, tissue
                  labels), and two cortical parcellation maps. The SRI24 atlas
                  enables multichannel atlas-to-subject image registration. It
                  is uniquely versatile in that it is equally suited for the
                  two fundamentally different atlas applications: label
                  propagation and spatial normalization. Label propagation,
                  herein demonstrated using diffusion tensor image fiber
                  tracking, is enabled by the increased sharpness of the SRI24
                  atlas compared with other available atlases. Spatial
                  normalization, herein demonstrated using data from a
                  young-old group comparison study, is enabled by its unbiased
                  average population shape property. For both propagation and
                  normalization, we also report the results of quantitative
                  comparisons with seven other published atlases: Colin27,
                  MNI152, ICBM452 (warp5 and air12), and LPBA40 (SPM5, FLIRT,
                  AIR). Our results suggest that the SRI24 atlas, although
                  based on 3T MR data, allows equally accurate spatial
                  normalization of data acquired at 1.5T as the comparison
                  atlases, all of which are based on 1.5T data. Furthermore,
                  the SRI24 atlas is as suitable for label propagation as the
                  comparison atlases and detailed enough to allow delineation
                  of anatomical structures for this purpose directly in the
                  atlas.},
  keywords =	 {brain atlas; multispectral magnetic resonance imaging;
                  diffusion tensor imaging; unbiased population registration;
                  spatial normalization; label propagation},
  doi =		 {10.1002/hbm.20906},
  pdf =		 {2010-rohlfing-hbm-sri24_atlas.pdf},
  PMID = 	 {20017133},
  NIHMSID =      166220,
  PMC =          {},
  url =          {http://www3.interscience.wiley.com/journal/123213661/abstract},
  category =	 {journal}
}

@Article{AshbHuttFrac:1998,
  author = 	 {Ashburner, John and Hutton, Chloe and Frackowiak, Richard
                  and Johnsrude, Ingrid and Price, Cathy and Friston, Karl},
  title = 	 {Identifying global anatomical differences: Deformation-based
                  morphometry},
  journal = 	 HumBrainMap,
  year = 	 1998,
  volume =	 6,
  number =	 {5--6},
  pages =	 {348--357},
  abstract =	 {The aim of this paper is to illustrate a method for
                  identifying macroscopic anatomical differences among the
                  brains of different populations of subjects. The method
                  involves spatially normalizing the structural MR images of a
                  number of subjects so that they all conform to the same
                  stereotactic space. Multivariate statistics are then applied
                  to the parameters describing the estimated nonlinear
                  deformations that ensue. To illustrate the method, we
                  compared the gross morphometry of male and female
                  subjects. We also assessed brain asymmetry, the effect of
                  handedness, and interactions among these effects.},
  keywords =	 {morphometrics; anatomy; spatial normalization; multivariate
                  analysis},
  doi =		 {10.1002/(SICI)1097-0193(1998)6:5/6<348::AID-HBM4>3.0.CO;2-P}
}

@InProceedings{Rohlfing:2003,
  author = 	 {Rohlfing, Torsten},
  title = 	 {Incremental Method for Computing the Intersection of
                  Discretely Sampled $m$-Dimensional Images with
                  $n$-Dimensional Boundaries}, 
  booktitle = 	 {Medical Imaging: Image Processing},
  pages =	 {1346--1354},
  year =	 2003,
  editor =	 {Sonka, Milan and Fitzpatrick, J. Michael},
  volume =	 5032,
  series =	 ProcSPIE,
  month =	 feb,
  abstract =     {This paper describes an algorithm for clipping of
                  m-dimensional objects that intersect a compact n-dimensional
                  rectangular area. The new algorithm is an extension of a
                  method for line clipping in three dimensions. Motivated by
                  the need for efficient algorithms for example when comparing
                  three-dimensional (3-D) images to each other, our method
                  allows for the incremental computation of the subset of
                  voxels in a discretely sampled image which are located
                  inside a second image. Limited fields of view (rectangular
                  regions of interest) in either image are easily
                  supported. Application of our algorithm does not require the
                  generation of an explicit geometrical description of the
                  image intersection. Besides its generality with respect to
                  the dimensions of the objects under consideration, our
                  clipping method solves the problem of discriminating between
                  points inside the clipping region and points on its edge,
                  which is important when problems such as voxel intensity
                  interpolation are only well-defined within the clipping
                  area.},
  keywords =     {clipping; ray casting; registration; performance},
  url =          {http://spiedl.aip.org/vsearch/servlet/VerityServlet?KEY=SPIEDL&smode=strresults&sort=rel&maxdisp=25&threshold=0&pjournals=SPIEDL&possible1=rohlfing&possible1zone=article&SMODE=strsearch&OUTLOG=NO&deliveryType=spiedlpdf&key=DISPLAY&docID=4&page=0&chapter=0},
  doi =          {10.1117/12.483556}
}

@Article{FrisHolmWors:1995,
  author =       {Friston, Karl J. and Holmes, A. P. and Worsley, K. J. and
                  Poline, J. B. and Frith, C. and Frackowiak, R. S. J.},
  title =        {Statistical Parametric Maps in Functional Imaging: A General
                  Linear Approach},
  journal =      HumBrainMap,
  year =         1995,
  volume =       2,
  pages =        {189--210},
  keyword =      {GLM,RFT},
  abstract =     {Statistical parametric maps are spatially extended
                  statistical processes that are used to test hypotheses about
                  regionally specific effects in neuroimaging data. The most
                  established sorts of statistical parametric maps
                  (e.g. Friston et al 1991, Worsley et al 1992) are based on
                  linear models, for example ANCOVA, correlation coefficients
                  and t tests. In the sense that these examples are all
                  special cases of the general linear model it should be
                  possible to implement them (and many others) within a
                  unified framework. We present here a general approach that
                  accommodates most forms of experimental layout and ensuing
                  analysis (designed experiments with fixed effects for
                  factors, covariates and interaction of factors). This
                  approach brings together two well established bodies of
                  theory (the general linear model and the theory of Gaussian
                  Fields) to provide a complete and simple framework for the
                  analysis of imaging data. The importance of this framework
                  is twofold: (i) Conceptual and mathematical simplicity, in
                  that the small number of operational equations used are the
                  same, irrespective of the complexity of the experiment or
                  nature of the statistical model and (ii) the generality of
                  the framework provides for great latitude in experimental
                  design and analysis.}
}

@Article{MillChriAmit:1993,
  author = 	 {Miller, Michael I. and Christensen, Gary E. and Amit, Yali
                  and Grenander, Ulf},
  title = 	 {Mathematical textbook of deformable neuroanatomies},
  journal = 	 PNAS,
  year = 	 1993,
  volume =	 90,
  number =	 24,
  pages =	 {11944-11948}
}

@Article{TzouLandPapa:2002,
  author = 	 {Tzourio-Mazoyer, N. and Landeau, B. and Papathanassiou,
                  D. and Crivello, F. and Etard, O. and Delcroix, N. and
                  Mazoyer, B. and Joliot, M.},
  title = 	 {Automated Anatomical Labeling of Activations in {SPM} Using
                  a Macroscopic Anatomical Parcellation of the {MNI} {MRI}
                  Single-Subject Brain},
  journal = 	 NeuroImage,
  year = 	 2002,
  volume =	 15,
  number =	 1,
  pages =	 {273--289},
  month =	 jan,
  abstract =	 {An anatomical parcellation of the spatially normalized
                  single-subject high-resolution T1 volume provided by the
                  Montreal Neurological Institute (MNI) (D. L. Collins et al.,
                  1998, Trans. Med. Imag. 17, 463~468) was performed. The MNI
                  single-subject main sulci were first delineated and further
                  used as landmarks for the 3D definition of 45 anatomical
                  volumes of interest (AVOI) in each hemisphere. This
                  procedure was performed using a dedicated software which
                  allowed a 3D following of the sulci course on the edited
                  brain. Regions of interest were then drawn manually with the
                  same software every 2 mm on the axial slices of the
                  high-resolution MNI single subject. The 90 AVOI were
                  reconstructed and assigned a label. Using this parcellation
                  method, three procedures to perform the automated anatomical
                  labeling of functional studies are proposed: (1) labeling of
                  an extremum defined by a set of coordinates, (2) percentage
                  of voxels belonging to each of the AVOI intersected by a
                  sphere centered by a set of coordinates, and (3) percentage
                  of voxels belonging to each of the AVOI intersected by an
                  activated cluster. An interface with the Statistical
                  Parametric Mapping package (SPM, J. Ashburner and
                  K. J. Friston, 1999, Hum. Brain Mapp. 7, 254~266) is
                  provided as a freeware to researchers of the neuroimaging
                  community. We believe that this tool is an improvement for
                  the macroscopical labeling of activated area compared to
                  labeling assessed using the Talairach atlas brain in which
                  deformations are well known. However, this tool does not
                  alleviate the need for more sophisticated labeling
                  strategies based on anatomical or cytoarchitectonic
                  probabilistic maps.},
  doi =		 {10.1006/nimg.2001.0978}
}

@Article{ShatMirzAdis:2008,
  author = 	 {Shattuck, David W. and Mirza, Mubeena and Adisetiyo, Vitria
                  and Hojatkashani, Cornelius and Salamon, Georges and Narr,
                  Katherine L. and Poldrack, Russell A. and Bilder, Robert
                  M. and Toga, Arthur W.},
  title = 	 {Construction of a {3D} probabilistic atlas of human cortical
                  structures},
  journal = 	 NeuroImage,
  year = 	 2008,
  volume =	 39,
  number =	 3,
  pages =	 {1064--1080},
  month =	 feb,
  abstract =	 {We describe the construction of a digital brain atlas
                  composed of data from manually delineated MRI data. A total
                  of 56 structures were labeled in MRI of 40 healthy, normal
                  volunteers. This labeling was performed according to a set
                  of protocols developed for this project. Pairs of raters
                  were assigned to each structure and trained on the protocol
                  for that structure. Each rater pair was tested for
                  concordance on 6 of the 40 brains; once they had achieved
                  reliability standards, they divided the task of delineating
                  the remaining 34 brains. The data were then spatially
                  normalized to well-known templates using 3 popular
                  algorithms: AIR5.2.5s nonlinear warp (Woods et al., 1998)
                  paired with the ICBM452 Warp 5 atlas (Rex et al., 2003),
                  FSLs FLIRT (Smith et al., 2004) was paired with its own
                  template, a skull-stripped version of the ICBM152 T1
                  average; and SPM5s unified segmentation method (Ashburner
                  and Friston, 2005) was paired with its canonical brain, the
                  whole head ICBM152 T1 average. We thus produced 3 variants
                  of our atlas, where each was constructed from 40
                  representative samples of a data processing stream that one
                  might use for analysis. For each normalization algorithm,
                  the individual structure delineations were then resampled
                  according to the computed transformations. We next computed
                  averages at each voxel location to estimate the probability
                  of that voxel belonging to each of the 56 structures. Each
                  version of the atlas contains, for every voxel, probability
                  densities for each region, thus providing a resource for
                  automated probabilistic labeling of external data types
                  registered into standard spaces; we also computed average
                  intensity images and tissue density maps based on the three
                  methods and target spaces. These atlases will serve as a
                  resource for diverse applications including meta-analysis of
                  functional and structural imaging data and other
                  bioinformatics applications where display of arbitrary
                  labels in probabilistically defined anatomic space will
                  facilitate both knowledge-based development and
                  visualization of findings from multiple disciplines.},
  keywords =	 {Probabilistic atlas; Brain mapping; Neuroanatomy; Brain;
                  MRI},
  doi =		 {10.1016/j.neuroimage.2007.09.031}
}

@Article{KvelLofaRyba:2009,
  author = 	 {Kvello, P\aa{}l and L\o{}faldli, Bjarte Bye and Rybak, J\"urgen and
                  Menzel, Randolf and Mustaparta, Hanna},
  title = 	 {Digital, three-dimensional average shaped atlas of the
                  heliothis virescens brain with integrated gustatory and
                  olfactory neurons},
  journal = 	 {Frontiers in Systems Neuroscience},
  year = 	 2009,
  volume =	 3,
  numpages =     14,
  abstract =     {We use the moth Heliothis virescens as model organism for
                  studying the neural network involved in chemosensory coding
                  and learning. The constituent neurons are characterised by
                  intracellular recordings combined with staining, resulting
                  in a single neuron identified in each brain preparation. In
                  order to spatially relate the neurons of different
                  preparations a common brain framework was required. We here
                  present an average shaped atlas of the moth brain. It is
                  based on 11 female brain preparations, each stained with a
                  fluorescent synaptic marker and scanned in confocal
                  laser-scanning microscope. Brain neuropils of each
                  preparation were manually reconstructed in the computer
                  software AMIRA, followed by generating the atlas using the
                  Iterative Shape Average Procedure. To demonstrate the
                  application of the atlas we have registered two olfactory
                  and two gustatory interneurons, as well as the axonal
                  projections of gustatory receptor neurons into the atlas,
                  visualising their spatial relationships. The olfactory
                  interneurons, showing the typical morphology of inner-tract
                  antennal lobe projection neurons, projected in the calyces
                  of the mushroom body and laterally in the protocerebral
                  lobe. The two gustatory interneurons, responding to sucrose
                  and quinine respectively, projected in different areas of
                  the brain. The wide projections of the quinine responding
                  neuron included a lateral area adjacent to the projections
                  of the olfactory interneurons. The sucrose responding neuron
                  was confined to the suboesophageal ganglion with dendritic
                  arborizations overlapping the axonal projections of the
                  gustatory receptor neurons on the proboscis. By serving as a
                  tool for the integration of neurons, the atlas offers visual
                  access to the spatial relationship between the neurons in
                  three dimensions, and thus facilitates the study of neuronal
                  networks in the Heliothis virescens brain. The moth standard
                  brain is accessible at
                  http://www.nt.ntnu.no/users/kvello/H_virescens_standardbrain/},
  keywords =     {insect, taste, olfaction, neuron, tree-dimensional
                  reconstruction},
  url =          {http://frontiersin.org/systemsneuroscience/paper/10.3389/neuro.06/014.2009/},
  doi =          {10.3389/neuro.06/014.2009}
}

@Article{JeffPottChan:2007,
  author = 	 {Jefferis, Gregory S.X.E. and Potter, Christopher J. and
                  Chan, Alexander M. and Marin, Elizabeth C. and Rohlfing,
                  Torsten and Maurer, Jr., Calvin R. and Luo, Liqun},
  title = 	 {Comprehensive Maps of {{\em Drosophila\/}} Higher Olfactory
                  Centers: Spatially Segregated Fruit and Pheromone
                  Representation},
  journal = 	 Cell,
  year = 	 2007,
  volume =	 128,
  number =	 6,
  pages =	 {1187--1203},
  month =	 mar,
  abstract =     {In {\em Drosophila\/}, $\approx$50 classes of olfactory
                  receptor neurons (ORNs) send axons to 50 corresponding
                  glomeruli in the antennal lobe. Uniglomerular projection
                  neurons (PNs) relay olfactory information to the mushroom
                  body (MB) and lateral horn (LH). Here, we combine
                  single-cell labeling and image registration to create
                  high-resolution, quantitative maps of the MB and LH for 35
                  input PN channels and several groups of LH neurons. We find
                  (1) PN inputs to the MB are stereotyped as previously shown
                  for the LH; (2) PN partners of ORNs from different sensillar
                  groups are clustered in the LH; (3) fruit odors are
                  represented mostly in the posterior-dorsal LH, whereas
                  candidate pheromone-responsive PNs project to the
                  anterior-ventral LH; (4) dendrites of single LH neurons each
                  overlap with specific subsets of PN axons. Our results
                  suggest that the LH is organized according to biological
                  values of olfactory input.},
  category =     {journal},
  url =
                  {http://www.cell.com/content/article/abstract?uid=PIIS0092867407002048},
  PMID =         {17382886},
  PMC =          {1885945}
}

@InProceedings{RohlMaurBlue:2003b,
  author = 	 {Rohlfing, Torsten and Maurer, Calvin R. and Bluemke, David
                  A. and Jacobs, Michael A.},
  title = 	 {An Alternating-Constraints Algorithm for Volume-Preserving
                  Non-Rigid Registration of Contrast-Enhanced {MR} Breast
                  Images},
  booktitle = 	 {Biomedical Image Registration -- Second International
                  Workshop, WBIR 2003, Philadelphia, PA, USA, June 23-24,
                  2003},
  pages =	 {291--300},
  year =	 2003,
  editor =	 {Gee, James C. and Maintz, J. B. Antoine and Vannier,
                  Michael W.},
  volume =	 {2717},
  series =	 LNCS,
  address =	 {Berlin/Heidelberg},
  month =	 jun,
  publisher =	 {Springer-Verlag},
  abstract =	 {We propose and evaluate in this work a novel optimization
                  strategy for intensity-based non-rigid image registration of
                  contrast-enhanced images with a volume-preservation
                  constraint. Since patient motion correction and volume
                  preservation are to some extent mutually exclusive goals,
                  one is usually faced with a trade-off between volume
                  preservation of contrast-enhancing structures and artifact
                  reduction. We address this problem by repeatedly applying
                  registration passes with alternating incompressibility
                  constraint weights. The novel optimization method alternates
                  between under-constrained registration (allowing the
                  elimination of motion artifacts in the subtraction images)
                  and over-constrained registration (enforcing volume
                  preservation of contrast-enhancing structures). We apply our
                  method to pre- and post-contrast MR breast images from 17
                  patients. We evaluate our method and compare it to
                  unconstrained and fixed constraint non-rigid registration by
                  blinded visual assessment of maximum intensity projections
                  of subtraction images. The alternating-constraints algorithm
                  was judged to reduce artifacts better then the fixed
                  constraint algorithm in 11 out of 17 patients and equally
                  well in the remaining 6. The results of this study show the
                  capability of our method to achieve volume preservation and
                  at the same time reduce artifacts very similar to what can
                  be achieved by unconstrained non-rigid registration.},
  keywords =	 {non-rigid registration; volume preservation;
                  contrast-enhanced breast MR images; regularization;
                  optimization; alternating constraints},
  url =          {http://www.springerlink.com/openurl.asp?genre=article&issn=0302-9743&volume=2717&spage=291}
}

@Article{ChriJohn:2001,
  author = 	 {Christensen, Gary E. and Johnson, Hans J.},
  title = 	 {Consistent image registration},
  journal = 	 IEEE-TMI,
  year = 	 2001,
  volume =	 20,
  number =	 7,
  pages =	 {568--582},
  month =	 jul,
  keywords =     {image registration, medical image processing, Fourier
                  series, biomedical MRI, computerised tomography, consistent
                  image registration, reverse transformation, forward
                  transformation, pairwise registration error, iterative
                  estimation, topology preservation, continuum mechanics laws, 
                  covariance structure, linear elastic material constraint,
                  MRI, CT, magnetic resonance imaging, medical diagnostic
                  imaging}
}
